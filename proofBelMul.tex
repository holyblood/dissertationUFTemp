\chapter{Proof for Higher-Order Properties of Bayesian Empirical Likelihood:
Multivariate Case}
\section{Proof of the Lemma 6}
\begin{proof}
First, we prove the lemma for the empirical likelihood.
	\begin{eqnarray*}
\frac{\partial\tilde{l}}{\partial\theta_{k}} & = & \frac{\partial}{\partial\theta_{k}}\frac{1}{n}\sum_{i=1}^{n}\log\frac{1}{n\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)}\\
 & = & -\frac{1}{n}\sum_{i=1}^{n}\frac{{\partial\nu^{T}} / {\partial\theta_{k}}g\left(X_{i},\theta\right)+\nu^{T}{\partial g\left(X_{i},\theta\right)} / {\partial\theta_{k}}}{1+\nu^{T}g\left(X_{i},\theta\right)}\\
 & = & -\frac{\partial\nu^{T}}{\partial\theta_{k}}\sum_{i=1}^{n}\frac{g\left(X_{i},\theta\right)}{n\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)}-\nu^{T}\sum_{i=1}^{n}\frac{{\partial g\left(X_{i},\theta\right)} / {\partial\theta_{k}}}{n\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)}\\
 & = & -\nu^{T}\sum_{i=1}^{n}\frac{{\partial g\left(X_{i},\theta\right)} / {\partial\theta_{k}}}{n\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)}.
\end{eqnarray*}
\begin{eqnarray*}
\frac{\partial^{2}\hat{l}}{\partial\theta_{j}\partial\theta_{k}} & = & -\frac{\partial\nu^{T}}{\partial\theta_{j}}\sum_{i=1}^{n}\frac{{\partial g\left(X_{i},\theta\right)} / {\partial\theta_{k}}}{n\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)}\\
 &  & -\nu^{T}\frac{1}{n}\sum_{i=1}^{n}-\frac{{\partial^{2}g\left(X_{i},\theta\right)} / {\partial\theta_{j}\partial\theta_{k}}\left(1+\nu^{T}g\left(X_{i},\theta\right)\right) }{\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)^{2}}\\
 & & +\nu^T \frac{1}{n}\sum_{i=1}^{n} \frac{{\partial g\left(X_{i},\theta\right)} / {\partial\theta_{k}}\left({\partial\nu^{T}} / {\partial\theta_{j}}g\left(X_{i},\theta\right)+\nu^{T}{\partial g\left(X_{i},\theta\right)} / {\partial\theta_{j}}\right)}{\left(1+\nu^{T}g\left(X_{i},\theta\right)\right)^{2}}.
\end{eqnarray*}

Let $g_{i}=\left(g_{j}\left(X_{i},\theta\right)\right)$, $\nabla g_{i}=\left({\partial g_{j}\left(X_{i},\theta\right)} / {\partial\theta_{k}}\right)$. By (\ref{eq:decreasing-theta-to-nu-2}), 

\begin{eqnarray*}
\frac{\partial\tilde{l}\left(\tilde{\theta}\right)}{\partial\theta\partial\theta^{T}}&=&-\frac{1}{n}\left\{ \sum_{i=1}^{n}\omega_{i}\frac{\partial g\left(X_{i},\tilde{\theta}\right)}{\partial\theta}-\nu^{T}\sum_{i=1}^{n}\omega_{i}^{2}g\left(X_{i},\tilde{\theta}\right)\frac{\partial g\left(X_{i},\tilde{\theta}\right)}{\partial\theta}\right\} ^{T}\left\{ \sum_{i=1}^{n}\omega_{i}^{2}g\left(X_{i},\tilde{\theta}\right)g^{T}\left(X_{i},\tilde{\theta}\right)\right\}^{-1} \\&&\left\{ \sum_{i=1}^{n}\omega_{i}\frac{\partial g\left(X_{i},\tilde{\theta}\right)}{\partial\theta}-\nu^{T}\sum_{i=1}^{n}\omega_{i}^{2}g\left(X_{i},\tilde{\theta}\right)\frac{\partial g\left(X_{i},\tilde{\theta}\right)}{\partial\theta}\right\} -\frac{\nu^{T}}{n}\sum_{i=1}^{n}\omega_{i}\frac{\partial^{2}g\left(X_{i},\tilde{\theta}\right)}{\partial\theta\partial\theta^{T}}\\&&+\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{2}\left\{ \nu^{T}\frac{\partial g\left(X_{i},\tilde{\theta}\right)}{\partial\theta}\right\} \left\{ \nu^{T}\frac{\partial g\left(X_{i},\tilde{\theta}\right)}{\partial\theta}\right\} ^{T}.
\end{eqnarray*}
By a similar argument as Lemma \ref{lem:finite-empirical-weight-moment}, we find 
\[
   \lim_{n\rightarrow\infty} \frac{\partial\tilde{l}\left(\tilde{\theta}\right)}{\partial\theta\partial\theta^{T}} = -\left\{E\nabla g (X,\theta_0) \right\}^T \left[E\left\{g (X,\theta_0)g^T (X,\theta_0)\right\}\right]^{-1} \left\{E\nabla g (X,\theta_0)\right\},
\]
and the limit is negative Godambe information matrix, which is negative definite. Hence, there exists an $N$, such that for sufficient large $n\ge N$, ${\partial\tilde{l}\left(\tilde{\theta}\right)} / {\partial\theta\partial\theta^{T}}$ is negative definite.

	Next, we prove the lemma for the exponentially tilted empirical likelihood.
	\begin{eqnarray*}
		\frac{\partial\tilde{l}\left(\theta\right)}{\partial\theta}	&=&	\frac{\partial}{\partial\theta} \left( \sum_{i=1}^{n}-\nu^{T}g\left(X_{i},\theta\right)-n\log\left[\sum_{j=1}^{n}\exp\left\{ -\nu^{T}g\left(X_{j},\theta\right)\right\} \right] \right) \\
	&=&	-\sum_{i=1}^{n}\left\{ \frac{\partial\nu^{T}}{\partial\theta}g\left(X_{i},\theta\right)+\nu^{T}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}\right\} \\
	&	&+n\frac{\sum_{j=1}^{n}\exp\left\{- \nu^{T}g\left(X_{j},\theta\right)\right\} \left\{ \partial\nu^{T}/\partial\theta g\left(X_{j},\theta\right)+\nu^{T}\partial g\left(X_{j},\theta\right)/\partial\theta\right\} }{\sum_{j=1}^{n}\exp\left\{ - \nu^{T}g\left(X_{j},\theta\right)\right\} }\\
	&=&	-\frac{\partial\nu^{T}}{\partial\theta}\sum_{i=1}^{n}g\left(X_{i},\theta\right)-\nu^{T}\sum_{i=1}^{n}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}+n\sum_{j=1}^{n}\hat{w}_{i}\left(\theta\right)\left\{ \frac{\partial\nu^{T}}{\partial\theta}g\left(X_{j},\theta\right)+\nu^{T}\frac{\partial g\left(X_{j},\theta\right)}{\partial\theta}\right\}\\ 
	&=&	-\frac{\partial\nu^{T}}{\partial\theta}\sum_{i=1}^{n}g\left(X_{i},\theta\right)-\nu^{T}\sum_{i=1}^{n}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}+n\nu^{T}\sum_{j=1}^{n}\hat{w}_{i}\left(\theta\right)\frac{\partial g\left(X_{j},\theta\right)}{\partial\theta}
	\end{eqnarray*}
	Using the similar argument as the empirical likelihood case, we have also,
	\[
\lim_{n\rightarrow\infty} \frac{\partial\tilde{l}\left(\tilde{\theta}\right)}{\partial\theta\partial\theta^{T}} = -\left\{E\nabla g (X,\theta_0) \right\}^T \left[E\left\{g (X,\theta_0)g^T (X,\theta_0)\right\}\right]^{-1} \left\{E\nabla g (X,\theta_0)\right\},.
\]
	By the similar calculation, we can find that the Hessian matrix of the Cressie-Read empirical likelihood is positive definite too.
	
\end{proof}
\section{Behavior Of Log Empirical Likelihood In  The Tail}

The Taylor expansion consists of  expanding the log empirical
likelihood and prior density around the mean and  then control
the tail part of the log empirical likelihood. In order to implement
this idea, the tail part of $\tilde{l}\left(\theta\right)$ must vanish
faster than the required polynomial order. In this section,
we will show that indeed the tail part of $\tilde{l}\left(\theta\right)$
vanishes at an exponential rate.
\begin{lemma}
\label{lemma:exponential-decay-tail-2} For any $\delta_{1}>0$, there
exist $\varepsilon_{1}>0$ and $N_{3}$, such that 
\[
\tilde{l}\left(\theta\right)-\tilde{l}\left(\tilde{\theta}\right)\le-\varepsilon,\ascv,
\]
for any $\left|B^T\left(\theta-\tilde{\theta}\right)\right|\ge\delta_{1}$
and $\theta\in H_n$, 
where $B$ is the Cholesky decomposition of
 $\left\{ n^{-1}\sum_{i=1}^{n}\partial g\left(X_{i},\tilde{\theta}\right)/\partial\theta\right\} ^{2}/\left\{ n^{-1}\sum_{i=1}^{n}g\left(X_{i},\tilde{\theta}\right)^{2}\right\} $
 \end{lemma}
\begin{proof}
By Assumption 6, we know that $\tilde{\theta}$ is the unique maximizer%

. Therefore, for any $\theta\neq\tilde{\theta}$, $\tilde{l}\left(\theta\right)<\tilde{l}\left(\tilde{\theta}\right)$.
The set 
\[
\left\{ \theta:\left|B^T\left(\theta-\tilde{\theta}\right)\right|\ge\delta_{1}\right\} \cap H_n
\]
is a compact set, and $\tilde{l}\left(\theta\right)$ is a continuous
function. Hence there exists a $\theta^{*}\in\left\{ \theta:\left|B^T\left(\theta-\tilde{\theta}\right)\right|\ge\delta_{1}\right\} \cap H_n$
, such that for any $\theta\in\left\{ \theta:\left|B^T\left(\theta-\tilde{\theta}\right)\right|\ge\delta_{1}\right\} \cap H_n$,
\[
\tilde{l}\left(\theta\right)\le\tilde{l}\left(\theta^{*}\right).
\]
Therefore, $\tilde{l}\left(\theta\right)\le\tilde{l}\left(\theta^{*}\right)<\tilde{l}\left(\tilde{\theta}\right)$, which is equivalent to 
\[
\tilde{l}\left(\theta\right)-\tilde{l}\left(\tilde{\theta}\right)\le\tilde{l}\left(\theta^{*}\right)-\tilde{l}\left(\tilde{\theta}\right)<0.
\]
Let $\varepsilon_{1}=\left\{ \tilde{l}\left(\tilde{\theta}\right)-\tilde{l}\left(\theta^{*}\right)\right\} /2$,
then we have 
\[
\tilde{l}\left(\theta\right)-\tilde{l}\left(\tilde{\theta}\right)\le\tilde{l}\left(\theta^{*}\right)-\tilde{l}\left(\tilde{\theta}\right)<\varepsilon_{1}.
\]

\end{proof}

\section{Higher-Order Derivatives}\label{app:high-order-der}

In order to expand around the mean, we need to control the
remainder terms in the Taylor expansion, which involves the finiteness of higher-order
derivatives of $\tilde{l}$. 
\begin{lemma}
\label{lem:control-higher-order-derivative-2}
For any $k=1,2,\ldots,$ $\left(u_{1},u_{2},\ldots,u_{k}\right)\subset\left\{ 1,2,\ldots,p\right\} $,
where some of $u_{i}$s can be equal. Let 
\[
D=\begin{cases}
\left|n^{-1}G^{T}\mathrm{diag}\left(\omega_{1}^{r},\omega_{2}^{r},\ldots,\omega_{n}^{r}\right)G\right|, & \text{for EL or ETEL,}\\
\left|n^{-1}\left(\begin{array}{cc}
G^{T}\mathrm{diag}\left(q_{1},\ldots,q_{n}\right)G & \left(q_{1},\ldots,q_{n}\right)G\\
\left(\left(q_{1},\ldots,q_{n}\right)G\right)^{T} & \sum_{i=1}^{n}q_{i}
\end{array}\right)\right|, & \text{for CREL.}
\end{cases}
\]
Then 
\[
\frac{\partial^{k}\tilde{l}\left(\theta\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{k}}}=D^{-r_{k}}P_{k}\left(M_{1},M_{2},\ldots,\nu,\mu\right),
\]
where $P_{k}$ is a polynomial, $u_{i}$ can be same, and each $M_{i}$
is empirical moment of higher order derivatives of G, i.e. $M_{i}$
has the form 
\[
\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{r}\prod_{j=1}^{p}\prod_{l_{j}}\frac{\partial^{l_{j}}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{j_{1}}}\partial\theta_{2}^{s_{j_{2}}}\cdots\partial\theta_{p}^{s_{j_{p}}}},
\]
where $\sum_{t=1}^{p}s_{j_{t}}=l_{j}$ , and some of $s_{j_{t}}$
can be zero. \end{lemma}
\begin{proof}
From previous lemma, we can get the 
\[
\frac{\partial\nu}{\partial\theta}=D^{-1}P_{1}\left(\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{r_{1}}\frac{\partial g_{j}\left(X_{i},\theta\right)}{\partial\theta_{s}},\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{r_{2}}g_{j}\left(X_{i},\theta\right),\ldots,,\nu,\mu\right).
\]
\begin{eqnarray*}
\frac{\partial\tilde{l}^{\mathrm{EL}}\left(\theta\right)}{\partial\theta} & = & \sum_{i=1}^{n}\frac{1}{1+\nu^{T}g\left(X_{i},\theta\right)}\left(\frac{\partial\nu^{T}}{\partial\theta}g\left(X_{i},\theta\right)+\nu^{T}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}\right)\\
 & = & \frac{\partial\nu}{\partial\theta}\frac{1}{n}\sum_{i=1}^{n}\omega_{i}\left(\theta\right)g\left(X_{i},\theta\right)+\nu^{T}\frac{1}{n}\sum_{i=1}^{n}\omega_{i}\left(\theta\right)\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta},
\end{eqnarray*}
\[
\frac{\partial\tilde{l}^{\mathrm{ET}}\left(\theta\right)}{\partial\theta}=-\frac{\partial\nu^{T}}{\partial\theta}\frac{1}{n}\sum_{i=1}^{n}g\left(X_{i},\theta\right)-\nu^{T}\frac{1}{n}\sum_{i=1}^{n}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}+\nu^{T}\sum_{i=1}^{n}\hat{w}_{i}\left(\theta\right)\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta},
\]
\begin{eqnarray*}
\frac{\partial\tilde{l}^{\mathrm{CR}}\left(\theta\right)}{\partial\theta} & = & -\frac{1}{\lambda+1}\sum_{i=1}^{n}\omega_{i}^{\lambda+1}\left(\frac{\partial\mu}{\partial\theta}+\frac{\partial\nu^{T}}{\partial\theta}g\left(X_{i},\theta\right)+\nu^{T}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}\right)\\
 & = & -\frac{1}{\lambda+1}\left(\frac{\partial\mu}{\partial\theta}\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{\lambda+1}+\frac{\partial\nu^{T}}{\partial\theta}\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{\lambda+1}g\left(X_{i},\theta\right)+\nu^{T}\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{\lambda+1}\frac{\partial g\left(X_{i},\theta\right)}{\partial\theta}\right).
\end{eqnarray*}
So for $k=1$, the lemma holds. Assume for $k=n$, the lemma holds,
for $k=n+1$, 
\begin{eqnarray*}
\frac{\partial^{n+1}\tilde{l}\left(\theta\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{n}}\partial\theta_{u_{n+1}}} & = &  \frac{\partial}{\partial\theta_{u_{n+1}}}\frac{\partial^{k}\tilde{l}\left(\theta\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{k}}}\\
&= &-r_{k}D^{-r_{k}-1}\left(\frac{\partial D}{\partial\theta}\sum_{i=1}^{k_{n}}\frac{\partial P_{k}}{\partial M_{i}}\frac{\partial M_{i}}{\partial\theta}+\frac{\partial P_{k}}{\partial\nu}\frac{\partial\nu}{\partial\theta}+\frac{\partial P_{k}}{\partial\mu}\frac{\partial\mu}{\partial\theta}\right)
\end{eqnarray*}
Note that the partial derivative of $P_{k}$ is still a polynomial.
And $D$ itself is a polynomial of $n^{-1}\sum_{i=1}^{n}\omega_{i}^{r}g_{j}\left(X_{i},\theta\right)g_{s}\left(X_{i},\theta\right)$,
and $\mu,\nu$. Next 
\begin{eqnarray*}
\frac{\partial M_{i}}{\partial\theta} & = & \frac{1}{n}\sum_{i=1}^{n}\left(r\omega_{i}^{r-1}\frac{\partial\omega_{i}}{\partial\theta}\prod_{j=1}^{p}\prod_{l_{j}}\frac{\partial^{l_{j}}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{j_{1}}}\partial\theta_{2}^{s_{j_{2}}}\cdots\partial\theta_{p}^{s_{j_{p}}}}+\omega_{i}^{r}\sum_{j=1}^{p}\sum_{l_{j}}\prod_{j=1}^{p}\prod_{l\neq l_{j}}\frac{\partial^{l}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{j_{1}}}\partial\theta_{2}^{s_{j_{2}}}\cdots\partial\theta_{p}^{s_{j_{p}}}}\frac{\partial^{l+1}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{1}}\cdots\partial\theta}\right)\\
 & = & \frac{r}{n}\sum_{i=1}^{n}\omega_{i}^{r-1}\prod_{j=1}^{p}\prod_{l_{j}}\frac{\partial^{l_{j}}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{j_{1}}}\partial\theta_{2}^{s_{j_{2}}}\cdots\partial\theta_{p}^{s_{j_{p}}}}\frac{\partial\omega_{i}}{\partial\theta} \\
 &=& +\sum_{j=1}^{p}\sum_{l_{j}}\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{r}\prod_{j=1}^{p}\prod_{l\neq l_{j}}\frac{\partial^{l}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{j_{1}}}\partial\theta_{2}^{s_{j_{2}}}\cdots\partial\theta_{p}^{s_{j_{p}}}}\frac{\partial^{l+1}g_{j}\left(X_{i},\theta\right)}{\partial\theta_{1}^{s_{1}}\cdots\partial\theta}.
\end{eqnarray*}
And by the procedure we calculating the first order derivative of
empirical log likelihood, we know the $\partial\omega_{i}/\partial\theta$
are the polynomial of terms like $M_{i}$, so for $k=n+1$, the higher
order derivative of empirical log likelihood has the similar form.
Hence, by mathematical induction, the lemma holds for all $n$. 
\end{proof}
By Lemma \ref{lem:control-higher-order-derivative-2}, the higher-order derivatives of log empirical likelihood are rational functions of the sample moments of higher-order derivatives of  $g$. We can anticipate
that higher order derivatives of log empirical likelihood can be bounded
in a small neighborhood of the true parameter when sample size is
large , provided the population moments of higher-order derivatives of function $g$ are finite. This we prove in the following lemma .


\begin{lemma}
\label{lem:bounded-high-order-der-2} Under Assumptions \ref{assu:consistency-m-est}, \ref{assu:lil-m-est}, \ref{assu:lil-m-est-2} and 
\ref{assu:finite-theoretic-moment},
there exist constants $\delta_{2}$, $C_{3}$ and $N_{4}$ such that
for any $\left|B^T\left(\theta-\tilde{\theta}\right)\right|\le\delta_{2}$
and $n>N_{4}$, any $j=1,\ldots,k$,%
\begin{comment}
need add consistency conditions for M-Estimator
\end{comment}
{} 
\begin{equation}
\left|\frac{\partial^{k}\tilde{l}\left(\theta\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{k}}}\right|\le C_{3}.\label{eq:bounded-higher-order-derivatives}
\end{equation}
\end{lemma}
\begin{proof}
By Lemma \ref{lem:finite-empirical-weight-moment}, we have 
\[
M_{j}=\frac{1}{n}\sum_{i=1}^{n}\omega_{i}^{r}\prod_{j=1}^{p}\prod_{l_{j}}\frac{\partial^{l_{j}}g_{j}\left(X_{i},\tilde{\theta}\right)}{\partial\theta_{1}^{s_{j_{1}}}\partial\theta_{2}^{s_{j_{2}}}\cdots\partial\theta_{p}^{s_{j_{p}}}}
\rightarrow E\left(\prod_{j=1}^{l}\frac{\partial^{k_{l}}g\left(X,\theta_{0}\right)}{\partial\theta_{1}^{k_{l1}}\partial\theta_{2}^{k_{l2}}\cdots\partial\theta_{p}^{k_{lp}}}\right)\ascv.
\]
 By Lemma 3, the higher order
derivatives are continuous functions. Hence for any small number $\varepsilon_{2}>0$,
there exists a constant $\delta_{2}$ such that whenever $\left|B^T\left(\theta-\tilde{\theta}\right)\right|\le\delta_{2}$,
\[
\left|\frac{\partial^{k}\tilde{l}\left(\theta\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{k}}}-\frac{\partial^{k}\tilde{l}\left(\tilde{\theta}\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{k}}}\right|<\varepsilon_{2}.
\]
By Lemma \ref{lem:control-higher-order-derivative-2}, there exists
a constant $N_{4}$, such that whenever $n>N_{4}$. 
\[
\left|\frac{\partial^{k}\tilde{l}\left(\theta\right)}{\partial\theta_{u_{1}}\partial\theta_{u_{2}}\cdots\partial\theta_{u_{k}}}-
\frac{P_{k}\left[ E\left(\prod_{j=1}^{l} \partial^{k_{l}}g\left(X,\theta_{0}\right) / \partial\theta_{1}^{k_{l1}}\partial\theta_{2}^{k_{l2}}\cdots\partial\theta_{p}^{k_{lp}} \right) ,\ldots,0,1\right]}{D^{r_{k}}}\right|
<\varepsilon_{2}.
\]
By assumption, all the moments are bounded when $k\le K+3$.
Then there exist a constant $C_{3}$, such that 
\[
D^{-r_{k}}P_{k}\left[E\left(\prod_{j=1}^{l}\frac{\partial^{k_{l}}g\left(X,\theta_{0}\right)}{\partial\theta_{1}^{k_{l1}}\partial\theta_{2}^{k_{l2}}\cdots\partial\theta_{p}^{k_{lp}}}\right) ,\ldots,0,1\right]\le C_{3},
\]
 %
\begin{comment}
change the length
\end{comment}
 which leads to (\ref{eq:bounded-higher-order-derivatives}). 
\end{proof}

\section{Expansion Near The $M$-Estimator}
\begin{lemma}
\label{lem:near-mean-2nd-order-bound-2}.  Under  Assumptions 1 and 2,there exists a $\delta_{3}>0$,
such that 
\[
\sum_{i=1}^{n}\log\hat{w}_{i}\left(\theta\right)-\sum_{i=1}^{n}\log\hat{w}_{i}\left(\tilde{\theta}\right)\le-\frac{1}{4}y^{2},
\]
for any $\theta\in\left\{ \theta:\left|B^T\left(\theta-\tilde{\theta}\right)\right|<\delta_{3}\right\} \cap H$
. \end{lemma}
\begin{proof}
By Taylor expansion, 
\begin{eqnarray*}
\frac{1}{n}\left\{ \sum_{i=1}^{n}\log\hat{w}_{i}\left(\theta\right)-\sum_{i=1}^{n}\log\hat{w}_{i}\left(\tilde{\theta}\right)\right\}  & = & \frac{\partial\tilde{l}\left(\tilde{\theta}\right)}{\partial\theta^T}\left(\theta-\tilde{\theta}\right)+\frac{1}{2}\left(\theta-\tilde{\theta}\right)^T\frac{\partial^{2}\tilde{l}\left(\theta^{*}\right)}{\partial\theta \partial\theta^T}\left(\theta-\tilde{\theta}\right),
\end{eqnarray*}
where $\left|\theta^{*}-\tilde{\theta}\right|\le\left|\theta-\tilde{\theta}\right|$.
By definition of $\tilde{\theta}$, the first term in above equation
is zero. By Lemma \ref{lem:control-higher-order-derivative-2}, we
know that ${\partial^{2}\tilde{l}\left(\theta^{*}\right)} / {\partial\theta \partial\theta^T}$
is a continuous matrix function in $\theta$. Thus there exists a $\delta_{3}$,
such that for any $\left|B^T \left(\theta^{*}-\tilde{\theta}\right)\right|\le\left|B^T\left(\theta-\tilde{\theta}\right)\right|<\delta_{3}$,
\[
\left|\left(\theta-\tilde{\theta}\right)^T\frac{\partial^{2}\tilde{l}\left(\theta^{*}\right)}{\partial\theta \partial\theta^T}\left(\theta-\tilde{\theta}\right)+\left|B^T\left(\theta-\tilde{\theta}\right)\right|^{2}\right|<\frac{1}{2}\left|B^T\left(\theta-\tilde{\theta}\right)\right|^{2}.
\]
Hence $\left(\theta-\tilde{\theta}\right)^T{\partial^{2}\tilde{l}\left(\theta^{*}\right)} / {\partial\theta \partial\theta^T}\left(\theta-\tilde{\theta}\right)<-\left|B^T\left(\theta-\tilde{\theta}\right)\right|^{2}/2$,
 so that, 
\[
\sum_{i=1}^{n}\log\hat{w}_{i}\left(\theta\right)-\sum_{i=1}^{n}\log\hat{w}_{i}\left(\tilde{\theta}\right)<\frac{1}{2}\times\frac{1}{2}\left|\sqrt{n}B^T\left(\theta-\tilde{\theta}\right)\right|^{2}=\frac{1}{4}y^{2}.
\]
\end{proof}
The next lemma plays a key role in expanding the posterior, and can be interpreted as an empirical likelihood version of the Edgeworth expansion. 
\begin{lemma}
\label{lem:central-expansion-lik-2} Under  Assumptions \ref{assu:consistency-m-est}, \ref{assu:lil-m-est}, \ref{assu:lil-m-est-2} and 
\ref{assu:finite-theoretic-moment}, then there exist $\delta_{4}$, $M_{3}$
and $N_{5}$, 
and $ A_4=\left\{ \theta:\left|B^T\left(\theta-\tilde{\theta}\right)\right|<\delta_{4}\right\} \cap H $,
 such that 
\[
\left|\int_{A_4}\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)-\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\diff n^{-\frac{1}{2}}Y\right|\le M_{1}n^{-\frac{1}{2}\left(K+3\right)},\:\ascv.
\]
\end{lemma}
\begin{proof}
First, we can choose $\delta_{2}$ small enough so that $\left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \subset H_{n}$.
\begin{eqnarray*}
 &  & \int_{\left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \cap H_{n}}\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)-\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\diff n^{-\frac{1}{2}}Y\\
 & = & \int_{\left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} }\exp\left(\sum_{i=1}^{n}\ln\hat{w}_{i}\left(\theta\right)-\sum_{i=1}^{n}\ln\hat{w}_{i}\left(\tilde{\theta}\right)\right)\\
 &  & \left[\exp\left(\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)-\sum_{i=1}^{n}\left(\ln\hat{w}_{i}\left(\theta\right)-\ln\hat{w}_{i}\left(\tilde{\theta}\right)\right)\right)-1\right]\diff n^{-\frac{1}{2}}Y.
\end{eqnarray*}
By Lemma \ref{lem:near-mean-2nd-order-bound-2}, and Taylor expansion, the
above equation can be bounded by 
\begin{eqnarray*}
 &  & \int_{\left\{ \left|B\left(\theta-\tilde{\theta}\right)\right|\le\delta_{2}\right\} }\exp\left(-\frac{Y^{T}Y}{4}\right)\left|\exp\left(-\frac{n^{-\frac{K+2}{2}}}{\left(K+4\right)!}\left[\left(\theta-\tilde{\theta}\right)\nabla\right]^{K+4}\hat{l}\left(\theta^{*}\right)\right)-1\right|\diff n^{-\frac{1}{2}}Y\\
 & = & n^{-\frac{1}{2}}\int_{\left\{ \sqrt{Y^{T}Y}\le\delta_{2}\sqrt{n}\right\} }\exp\left(-\frac{Y^{T}Y}{4}\right)\left|\exp\left(-\frac{n^{-\frac{K+2}{2}}}{\left(K+4\right)!}\left(Y^{T}B^{-T}\nabla\right)^{K+4}\hat{l}\left(\theta^{*}\right)\right)-1\right|\diff Y.
\end{eqnarray*}
By Lemma \ref{lem:control-higher-order-derivative-2}, we know that $\nabla^{K+4}\hat{l}\left(\theta^{*}\right)$
are bounded by some constants. Note that for any $Y$, and any vector
$a$, there exists a constant $C_{1}$, such that 
\begin{equation}
\left(Y^{T}a\right)^{2}\le C_{1}\left(Y^{T}Y\right),\label{eq:average-inequality}
\end{equation}
so we can bounded the above equation by 
\[
n^{-\frac{1}{2}}\int_{\left\{ \sqrt{Y^{T}Y}\le\delta_{2}\sqrt{n}\right\} }\exp\left(-\frac{Y^{T}Y}{4}\right)\left(\exp\left(-n^{-\frac{K+2}{2}}C_{3}\left(Y^{T}Y\right)^{\frac{K+4}{2}}\right)-1\right)\diff Y,
\]
where $C_{3}=C_{1}^{\frac{K+4}{2}}$. Denote the above integrand to
be $F\left(Y,\sqrt{n}\right)$. We can the inequality in this lemma
if we can prove the following 
\begin{equation}
\lim_{n\rightarrow\infty}\frac{n^{-\frac{1}{2}}\int_{\left\{ \sqrt{Y^{T}Y}\le\delta_{2}\sqrt{n}\right\} }F\left(Y,\sqrt{n}\right)\diff Y}{n^{-\frac{1}{2}\left(K+3\right)}}=C_{2},\label{eq:lim-rhs-vs-lfs-inequality}
\end{equation}
for some constant $C_{2}<\infty$. Let $t=\sqrt{n}$, and relax $t\in\mathbb{R}^{+}$.
The the above formula can be written as 
\[
\frac{\int_{\left\{ \sqrt{Y^{T}Y}\le\delta_{2}t\right\} }F\left(Y,t\right)\diff Y}{t^{-K-2}}.
\]
Take the derivatives of both numerator and denominator with respect
to $t$. For the denominator $\left(t^{-K-2}\right)'=-\left(K+2\right)t^{-K-3}.$
For the numerator, we change to $n$ dimensional spherical coordinate
system, 
\begin{eqnarray*}
Y_{1} & = & r\cos\left(\varphi_{1}\right),\\
Y_{2} & = & r\sin\left(\varphi_{1}\right)\cos\left(\varphi_{2}\right),\\
 & \vdots\\
Y_{p} & = & r\sin\left(\varphi_{1}\right)\sin\left(\varphi_{2}\right)\cdots\sin\left(\varphi_{p-1}\right).
\end{eqnarray*}
So the numerator can be written as 
\begin{eqnarray*}
 &  & \int_{\left\{ r\le\delta_{2}t\right\} }\exp\left(-\frac{r^{2}}{4}\right)\left(\exp\left(-C_{3}t^{-K-2}r^{K+4}\right)-1\right)\\
 &  & \times r^{p-1}\sin^{p-2}\left(\varphi_{1}\right)\sin^{p-3}\left(\varphi_{2}\right)\cdots\sin\left(\varphi_{p-2}\right)\diff r\diff\varphi_{1}\cdots\diff\varphi_{p-1}\\
 & = & \int_{0}^{2\pi}\diff\varphi_{p-1}\int_{0}^{\pi}\sin^{p-2}\left(\varphi_{1}\right)\diff\varphi_{1}\cdots\int_{0}^{\pi}\sin\left(\varphi_{p-2}\right)\diff\varphi_{p-2}\\
 &  & \times\int_{0}^{\delta_{2}t}\exp\left(-\frac{r^{2}}{4}\right)\left(\exp\left(-C_{3}t^{-K-4}r^{K+4}\right)-1\right)r^{p-1}\diff r\\
 & \le & 2\pi\left(\pi\right)^{p-2}\int_{0}^{\delta_{2}t}\exp\left(-\frac{r^{2}}{4}\right)\left(\exp\left(-C_{3}t^{-K-2}r^{K+4}\right)-1\right)r^{p-1}\diff r\\
 & = & 2\pi^{p-1}\int_{0}^{\delta_{2}t}\exp\left(-\frac{r^{2}}{4}\right)\left(\exp\left(-C_{3}t^{-K-2}r^{K+4}\right)-1\right)r^{p-1}\diff r.
\end{eqnarray*}
 
\begin{eqnarray*}
 &  & \frac{\diff}{\diff t}\int_{0}^{\delta_{2}t}\exp\left(-\frac{r^{2}}{4}\right)\left(\exp\left(-C_{3}t^{-K-2}r^{K+4}\right)-1\right)r^{p-1}\diff r\\
 & = & \int_{0}^{\delta_{2}t}-\left(K+2\right)t^{-K-3}\left(-C_{3}r^{K+4}\right)\exp\left(-\frac{r^{2}}{4}\right)\exp\left(-C_{3}t^{-K-2}r^{K+4}\right)r^{p-1}\diff r\\
 &  & +\exp\left(-\frac{\delta_{2}^{2}t^{2}}{4}\right)\left(\exp\left(-C_{3}t^{-K-2}\left(\delta_{2}t\right)^{K+4}\right)-1\right)\\
 & \le & C_{3}\left(K+2\right)t^{-K-3}\int_{0}^{\delta_{2}t}r^{K+p+3}\exp\int_{A\cap H_{n}}\exp\left(-\frac{Y^{T}Y}{4}\right)\left|\alpha_{h}\left(Y,n\right)\right|\diff Y\\
 &  & \left(-\left(\frac{1}{4}-C_{3}t^{-K-2}r^{K+2}\right)r^{2}\right)\diff r+\exp\left(-\left(\frac{1}{4}-C_{3}\delta_{2}^{K+2}\right)\delta_{2}^{2}t^{2}\right)-\exp\left(-\frac{\delta_{2}^{2}t^{2}}{4}\right).
\end{eqnarray*}
If 
\[
\delta_{2}<\sqrt[K+2]{\frac{1}{4C_{3}}},
\]
then 
\[
\frac{1}{4}-C_{3}\delta_{2}^{K+2}>0,
\]
hence 
\[
\lim_{t\rightarrow+\infty}\frac{\exp\left(-\left(\frac{1}{4}-C_{3}\delta_{2}^{K+2}\right)\delta_{2}^{2}t^{2}\right)-\exp\left(-\frac{\delta_{2}^{2}t^{2}}{4}\right)}{-\left(K+2\right)t^{-K-3}}=0.
\]
For the first term in derivative of numerator, we have for any $t>0$.
\begin{eqnarray*}
 &  & \int_{0}^{\delta_{2}t}r^{K+p+3}\exp\left(-\left(\frac{1}{4}-C_{3}t^{-K-2}r^{K+2}\right)r^{2}\right)\diff r\\
 & \le & \int_{0}^{\delta_{2}t}r^{K+p+3}\exp\left(-\left(\frac{1}{4}-C_{3}\delta_{2}^{K+2}\right)r^{2}\right)\diff r\\
 & \le & \int_{\mathbb{R}}\left|r\right|^{K+p+3}\exp\left(-\left(-\frac{1}{4}-C_{3}\delta_{2}^{K+2}\right)r^{2}\right)\diff r<+\infty.
\end{eqnarray*}
Therefore, there exists a constant $C_{2}$, such that 
\begin{eqnarray*}
 &  & \lim_{t\rightarrow+\infty}\frac{C_{3}\left(K+2\right)t^{-K-3}\int_{0}^{\delta_{2}t}r^{K+p+3}\exp\left(-\left(\frac{1}{4}-C_{3}t^{-K-2}r^{K+2}\right)r^{2}\right)\diff r}{-\left(K+2\right)t^{-K-3}}\\
 & = & -C_{3}\lim_{t\rightarrow+\infty}\int_{0}^{\delta_{2}t}r^{K+p+3}\exp\left(-\left(\frac{1}{4}-C_{3}t^{-K-2}r^{K+2}\right)r^{2}\right)\diff r=C_{2}.
\end{eqnarray*}
By L'Hostiple's rule, we have \eqref{lim-rhs-vs-lfs-inequality} holds,
and therefore, the lemma holds.
\end{proof}

\begin{lemma}
\label{lem:central-expansion-post-prod-2}%
 Under  Assumptions \ref{assu:consistency-m-est}, \ref{assu:lil-m-est}, \ref{assu:lil-m-est-2} and 
\ref{assu:finite-theoretic-moment},
  there exists  $\delta_{4}>0$, and constants
$M_{4}$, $N_{6}$, such that 
\begin{equation}
\left|\int_{\left\{ \left|B\left(\theta-\tilde{\theta}\right)\right|\le\delta\right\} \cap H_{n}}\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)-\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)\diff n^{-\frac{1}{2}}Y\right|\le M_{2}n^{-\frac{1}{2}\left(K+2\right)},\:\ascv.\label{eq:central-exp-post-2}
\end{equation}
\end{lemma}
\begin{proof}
Apply Taylor expansion to $\hat{l}\left(\theta\right)$ around $\tilde{\theta}$,
for any $\theta\in H_{n}$, there exists a $\theta^{*}$satisfies
$\left|B\left(\theta^{*}-\tilde{\theta}\right)\right|\le\left|B\left(\theta-\tilde{\theta}\right)\right|$,
such that, 
\begin{eqnarray*}
\hat{l}\left(\theta\right) & = & \hat{l}\left(\tilde{\theta}\right)+\nabla\hat{l}\left(\tilde{\theta}\right)\left(\theta-\tilde{\theta}\right)+\frac{1}{2}\left(\theta-\tilde{\theta}\right)^{T}\frac{\partial^{2}\hat{l}\left(\tilde{\theta}\right)}{\partial\theta^{T}\partial\theta}\left(\theta-\tilde{\theta}\right)+\sum_{k=3}^{K+3}\frac{1}{k!}\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{k}\hat{l}\left(\tilde{\theta}\right)\\
 &  & +\frac{1}{\left(K+4\right)!}\left[\left(\theta-\tilde{\theta}\right)\nabla\right]^{K+4}\hat{l}\left(\theta^{*}\right)\\
 & = & \hat{l}\left(\tilde{\theta}\right)-\frac{1}{2}Y^{T}Yn^{-1}+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k}{2}}++\frac{1}{\left(K+4\right)!}\left[\left(\theta-\tilde{\theta}\right)\nabla\right]^{K+4}\hat{l}\left(\theta^{*}\right).
\end{eqnarray*}
Now we have 
\begin{eqnarray*}
 &  & \left|\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)-\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)\right|\\
 &  & \le\left|\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)-\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho_{K}\left(\theta\right)\right|\\
 &  & +\left|\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho_{K}\left(\theta\right)-\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)\right|\\
 &  & \le\left|\rho_{K}\left(\theta\right)\right|\exp\left(n\left(\hat{l}\left(\theta\right)-\hat{l}\left(\tilde{\theta}\right)\right)\right)\left|\exp\left(n\left(\hat{l}\left(\tilde{\theta}\right)-\frac{1}{2}Y^{T}Yn^{-1}+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}-\hat{l}\left(\theta\right)\right)\right)-1\right|\\
 &  & +\exp\left(n\left(\hat{l}\left(\theta\right)-\hat{l}\left(\tilde{\theta}\right)\right)\right)\left|\rho_{K}\left(\theta\right)-\rho\left(\theta\right)\right|.
\end{eqnarray*}
For the first part of the above formula, by Lemma \ref{lem:central-expansion-lik-2},
we have it to be bounded by 
\[
\max_{\theta\in\left\{ \left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \cap H_{n}\right\} }\rho_{K}\left(\theta\right)M_{1}n^{-\frac{1}{2}\left(K+3\right)}.
\]
For the second part, by Lemma \ref{lem:near-mean-2nd-order-bound-2}, Taylor
expansion in $\rho\left(\theta\right)$, and \eqref{average-inequality},
we have the upper bound to be 
\begin{eqnarray*}
 &  & \int_{\left\{ Y^{T}Y\le\delta_{2}^{2}n\right\} }\exp\left(-\frac{Y^{T}Y}{4}\right)\frac{n^{-\frac{K+1}{2}}}{\left(K+1\right)!}\left(Y^{T}B^{-T}\nabla\right)^{K+1}\rho\left(\theta^{*}\right)\diff n^{-\frac{1}{2}}Y\\
 & \le & \frac{1}{\left(K+1\right)!}\max_{\theta\in\left\{ \left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \cap H_{n}\right\} }\left|\nabla^{K+1}\rho\left(\theta^{*}\right)\right|\int_{\left\{ Y^{T}Y\le\delta_{2}^{2}n\right\} }\exp\left(-\frac{Y^{T}Y}{4}\right)C_{1}^{\frac{K+1}{2}}\left(Y^{T}Y\right)^{\frac{K+1}{2}}\diff Yn^{-\frac{K+2}{2}}\\
 & \le & \frac{C_{1}^{\frac{K+1}{2}}}{\left(K+1\right)!}\max_{\theta\in\left\{ \left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \cap H_{n}\right\} }\left|\nabla^{K+1}\rho\left(\theta\right)\right|\int_{\mathbb{R}^{p}}\exp\left(-\frac{Y^{T}Y}{4}\right)\left(Y^{T}Y\right)^{\frac{K+1}{2}}\diff Yn^{-\frac{K+2}{2}}\\
 & = & \frac{C_{1}^{\frac{K+1}{2}}}{\left(K+1\right)!}\max_{\theta\in\left\{ \left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \cap H_{n}\right\} }\left|\nabla^{K+1}\rho\left(\theta\right)\right|2\pi^{p-1}\int_{0}^{\infty}\exp\left(-\frac{r^{2}}{4}\right)r^{K+1}r^{p-1}\diff rn^{-\frac{K+2}{2}}\\
 & = & \left[\frac{2\pi^{p-1}C_{1}^{\frac{K+1}{2}}}{\left(K+1\right)!}\max_{\theta\in\left\{ B\left(\theta-\tilde{\theta}\right)\le\delta_{2}\right\} \cap H_{n}}\left|\nabla^{K+1}\rho\left(\theta\right)\right|\int_{0}^{\infty}r^{p+K}\exp\left(-\frac{r^{2}}{4}\right)\diff r\right]n^{-\frac{K+2}{2}}
\end{eqnarray*}
Since $p\ge1$, we have \eqref{central-exp-post-2} holds.

\end{proof}

\section{Proof Of The Fundamental Theorem For Expansion}\label{app-proof-fun-thm}

We first intuitively derive %
\begin{comment}
add expansion polynomial
\end{comment}
. First, we expand 
\begin{eqnarray*}
 &  & \exp\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\\
 & = & \sum_{i=0}^{K+1}\frac{1}{i!}\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)^{i}\\
 & = & 1+\sum_{i=1}^{K+1}\frac{1}{i!}\sum_{\sum_{u=3}^{K+3}m_{u,i}=i}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}n^{-\frac{1}{2}\sum_{u=3}^{K+3}m_{u,i}\left(u-2\right)}.
\end{eqnarray*}
Then we product the above expansion by $\rho_{K}$, 
\begin{eqnarray*}
 &  & \exp\left(\sum_{k=3}^{K+3}\frac{1}{k!}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)\\
 & = & \left[1+\sum_{i=1}^{K+1}\frac{1}{i!}\sum_{\sum_{u=3}^{K+3}m_{u,i}=i}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}n^{-\frac{1}{2}\sum_{u=3}^{K+3}m_{u,i}\left(u-2\right)}\right]\\
 &  & \left(\rho\left(\tilde{\theta}\right)+\sum_{j=1}^{K}\delta_{j}\rho n^{-\frac{j}{2}}\right)\\
 & = & \rho\left(\tilde{\theta}\right)+\sum_{j=1}^{K}\delta_{j}\rho n^{-\frac{j}{2}}+\rho\left(\tilde{\theta}\right)\sum_{i=1}^{K+1}\frac{1}{i!}\\
 &  & \sum_{\sum_{u=3}^{K+3}m_{u,i}=i}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}n^{-\frac{1}{2}\sum_{u=3}^{K+3}m_{u,i}\left(u-2\right)}\\
 &  & +\left[\sum_{i=1}^{K+1}\frac{1}{i!}\sum_{\sum_{u=3}^{K+3}m_{u,i}=i}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}n^{-\frac{1}{2}\sum_{u=3}^{K+3}m_{u,i}\left(u-2\right)}\right]\sum_{j=1}^{K}\delta_{j}\rho n^{-\frac{j}{2}}.
\end{eqnarray*}
For the third term in above equation, we change the summation index.
Let $\sum_{u=3}^{K+3}m_{u,i}\left(u-2\right)=h$. Note that for any
$\sum_{u=3}^{K+3}m_{u,i}=i$, $i\le h\le i\left(K+1\right)$, $h/\left(K+1\right)\le i\le h$.
Thus the third term summation can be rearranged as 
\[
\sum_{h=1}^{\left(K+1\right)^{2}}\left[\rho\left(\tilde{\theta}\right)\sum_{\frac{h}{K+1}\le i\le h}\frac{1}{i!}\sum_{I_{i,h}}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}\right]n^{-\frac{h}{2}}.
\]
Similarly for the fourth term, let $\sum_{u=3}^{K+3}m_{u,i}\left(u-2\right)+j=h$,
then the summation can be rearranged as 
\[
\sum_{h=2}^{\left(K+1\right)^{2}+K}\left[\sum_{j=1}^{h-1}\delta_{j}\rho\sum_{\frac{h-j}{K+1}\le i\le h-j}\frac{1}{i!}\sum_{I_{i,h-j}}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}\right]n^{-\frac{h}{2}}.
\]
We collect the same order term of $n$, and denote the summation of
all the terms with order higher than $K$ to be $R_{K}\left(Y\right)$,
then we get the product as 
\begin{eqnarray*}
 &  & \rho\left(\tilde{\theta}\right)+\left(\delta_{1}\rho+\rho\left(\tilde{\theta}\right)\delta_{3}\hat{l}\right)n^{-\frac{1}{2}}\\
 &  & +\sum_{h=2}^{K}\left[\delta_{h}\rho+\sum_{j=0}^{h-1}\delta_{j}\rho\sum_{\frac{h-j}{K+1}\le i\le h-j}\frac{1}{i!}\sum_{I_{i,h-j}}\binom{i}{m_{3,i},m_{4,i},\ldots,m_{K+3,i}}\prod_{u=3}^{K+3}\left(\delta_{u}\hat{l}\right)^{m_{u,i}}\right]n^{-\frac{h}{2}}+R_{K}\left(Y\right).
\end{eqnarray*}
 Integral over any Borel set $A\cap H_{n}$, we can get the polynomial
$P_{K}\left(A,n\right)$. Now we can prove the main theorem %
\begin{comment}
add ref to main theorem
\end{comment}
. 
\begin{proof}
Let $A_{1}=\left\{ \left|Y\right|_{2}\ge\delta_{2}\sqrt{n}\right\} $
and $A_{2}=\left\{ \left|Y\right|_{2}<\delta_{2}\sqrt{n}\right\} $.
Then 
\begin{eqnarray*}
 &  & \left|\int_{A\cap H_{n}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)\diff n^{-\frac{1}{2}}Y-P_{K}\left(A,n\right)\right|\\
 & = & \left|\int_{A\cap H_{n}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \left|\int_{A\cap H_{n}\cap A_{1}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 &  & +\left|\int_{A\cap H_{n}\cap A_{2}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|.
\end{eqnarray*}


For the first term%
\begin{comment}
change the first second term ref into ref eq
\end{comment}
, by Lemma \ref{lemma:exponential-decay-tail-2}, we have
\begin{eqnarray*}
 &  & \left|\int_{A\cap H_{n}\cap A_{1}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \int_{A\cap H_{n}\cap A_{1}}\exp\left(n\left(\hat{l}\left(\theta\right)-\hat{l}\left(\tilde{\theta}\right)\right)\right)\rho\left(\theta\right)\diff n^{-\frac{1}{2}}Y\\
 &  & +\left|\int_{A\cap H_{n}\cap A_{1}}\exp\left(-\frac{Y^{T}Y}{4}-\frac{Y^{T}Y}{4}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \exp\left(-n\varepsilon\right)\int_{A\cap H_{n}\cap A_{1}}\rho\left(\theta\right)\diff B\left(\theta-\tilde{\theta}\right)\\
 &  & +\exp\left(-\frac{\delta_{2}^{2}n}{4}\right)\left|\int_{A\cap H_{n}\cap A_{1}}\exp\left(-\frac{Y^{T}Y}{4}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \exp\left(-n\varepsilon\right)\int_{\mathbb{R}}\rho\left(\theta\right)\diff B\left(\theta-\tilde{\theta}\right)+\exp\left(-n\frac{\delta_{2}^{2}}{4}\right)\sum_{h=0}^{K}\left(\int_{A\cap H_{n}}\exp\left(-\frac{Y^{T}Y}{4}\right)\left|\alpha_{h}\left(Y,n\right)\right|\diff Y\right)n^{-\frac{h+1}{2}}.
\end{eqnarray*}
Note that the above terms are exponentially decreasing with respect
to $n$, so there exists an $N_{3}$, and $M_{3}$, such that for
any $n\ge N_{3}$, 
\[
\left|\int_{A\cap H_{n}\cap A_{1}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\le M_{3}n^{-\frac{K+2}{2}}.
\]


For the second term, by \lemref{central-expansion-post-prod}, we
have 
\begin{eqnarray*}
 &  & \left|\int_{A\cap H_{n}\cap A_{2}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \left|\int_{A\cap H_{n}\cap A_{2}}\prod_{i=1}^{n}\frac{\hat{w}_{i}\left(\theta\right)}{\hat{w}_{i}\left(\tilde{\theta}\right)}\rho\left(\theta\right)-\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)\diff n^{-\frac{1}{2}}Y\right|\\
 &  & +\left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & M_{2}n^{-\frac{K+2}{2}}\\
 &  & +\left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|.
\end{eqnarray*}
For the second term of above, we add and subtract $R_{K}\left(Y\right)$
in integrand, and by Taylor expansion, 
\begin{eqnarray*}
 &  & \left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{1}{2}Y^{T}Y+\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)\rho_{K}\left(\theta\right)-\exp\left(-\frac{Y^{T}Y}{2}\right)\sum_{h=0}^{K}\alpha_{h}\left(Y,n\right)n^{-\frac{h}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)\rho_{K}\left(\theta\right)\left[\exp\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)-\sum_{i=0}^{K+1}\frac{1}{i!}\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)^{i}\right]\diff n^{-\frac{1}{2}}Y\right|\\
 &  & +\left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)R_{K}\left(Y\right)\diff n^{-\frac{1}{2}}Y\right|\\
 & = & \left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)\rho_{K}\left(\theta\right)\frac{1}{\left(K+2\right)!}\exp\left(L\right)\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)^{K+2}\diff n^{-\frac{1}{2}}Y\right|\\
 &  & +\left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)R_{K}\left(Y\right)\diff n^{-\frac{1}{2}}Y\right|,
\end{eqnarray*}
where $\left|L\right|\le\left|\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right|$.
We know that $R_{K}\left(Y\right)$ is a polynomial with order $n^{-\frac{1}{2}\left(K+1\right)}$,
so there exists an $M_{3}$, such that 
\[
\left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)R_{K}\left(Y\right)\diff n^{-\frac{1}{2}}Y\right|\le M_{3}n^{-\frac{1}{2}\left(K+2\right)}.
\]
For the first term, 

\begin{eqnarray}
 &  & \left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)\rho_{K}\left(\theta\right)\frac{1}{\left(K+2\right)!}\exp\left(L\right)\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)^{K+2}\diff n^{-\frac{1}{2}}Y\right|\label{eq:1}\\
 & \le & \frac{1}{\left(K+2\right)!}\left|\int_{A\cap H_{n}\cap A_{2}}\exp\left(-\frac{Y^{T}Y}{2}\right)\rho_{K}\left(\theta\right)\exp\left(\left|\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right|\right)\left(\sum_{k=3}^{K+3}\delta_{k}\hat{l}n^{-\frac{k-2}{2}}\right)^{K+2}\diff n^{-\frac{1}{2}}Y\right|\nonumber \\
 & = & \frac{1}{\left(K+2\right)!}\Bigg|\int_{A\cap H_{n}\cap A_{2}}\rho_{K}\left(\theta\right)\exp\left(-n\left\{ \frac{\left(\theta-\tilde{\theta}\right)^{T}B^{2}\left(\theta-\tilde{\theta}\right)}{2}-\left|\sum_{k=3}^{K+3}\frac{\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{k}\hat{l}}{k!}\right|\right\} \right)\nonumber \\
 &  & \left\{ n\sum_{k=3}^{K+3}\frac{\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{k}\hat{l}}{k!}\right\} ^{K+2}\diff B\left(\theta-\tilde{\theta}\right)\Bigg|.\nonumber 
\end{eqnarray}
We need $\delta_{2}$sufficiently small, so that there exist an $C_{4}$
and $C_{5}$, such that 
\begin{eqnarray*}
\frac{\left(\theta-\tilde{\theta}\right)^{T}B^{2}\left(\theta-\tilde{\theta}\right)}{2}-\left|\sum_{k=3}^{K+3}\frac{\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{k}\hat{l}}{k!}\right| & \ge & C_{4}\left(\theta-\tilde{\theta}\right)^{T}B^{2}\left(\theta-\tilde{\theta}\right),\\
\sum_{k=3}^{K+3}\frac{\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{k}\hat{l}}{k!} & \le & C_{5}\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{3}\hat{l}.
\end{eqnarray*}
Hence, \eqref{1} can be bounded by 
\begin{eqnarray*}
 &  & \frac{n^{K+2}}{\left(K+2\right)!}\left|\int_{A\cap H_{n}\cap A_{n}}\exp\left(-nC_{4}\left(\theta-\tilde{\theta}\right)^{T}B^{2}\left(\theta-\tilde{\theta}\right)\right)\left\{ C_{5}\left[\left(\theta-\tilde{\theta}\right)^{T}\nabla\right]^{3}\hat{l}\right\} ^{K+2}\diff B\left(\theta-\tilde{\theta}\right)\right|\\
 & \le & \frac{C_{5}^{K+2}n^{K+2}}{\left(K+2\right)!}\left|\int_{A\cap H_{n}}\exp\left(-C_{4}Y^{T}Y\right)\left(\delta_{3}\hat{l}\right)^{K+2}n^{-\frac{3\left(K+2\right)}{2}}\diff n^{-\frac{1}{2}}Y\right|\\
 & \le & \frac{C_{5}^{K+2}}{\left(K+2\right)!}\left|\int_{A\cap H_{n}}\exp\left(-C_{4}Y^{T}Y\right)\left(\delta_{3}\hat{l}\right)^{K+2}\diff Y\right|n^{-\frac{K+3}{2}}.
\end{eqnarray*}
Add all the parts together, we get the inequality in Theorem \ref{thm:main-theorem-2}%
\begin{comment}
add ref to main theorem
\end{comment}
.
\end{proof}

